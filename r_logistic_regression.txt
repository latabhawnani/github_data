
mydata <- read.csv(file.choose(), header = T)
str(mydata)
mydata$admit <- as.factor(mydata$admit)
mydata$rank <- as.factor(mydata$rank)

# Partition data - train (80%) & test (20%)
set.seed(1234)
ind <- sample(2, nrow(mydata), replace = T, prob = c(0.8, 0.2))
train <- mydata[ind==1,]
test <- mydata[ind==2,]

# Logistic regression model
mymodel <- glm(admit ~ gre + gpa + rank, data = train, family = 'binomial')
summary(mymodel)

# Prediction
p1 <- predict(mymodel, train, type = 'response')
head(p1)
head(train)

# Misclassification error - train data
pred1 <- ifelse(p1>0.5, 1, 0)
tab1 <- table(Predicted = pred1, Actual = train$admit)
tab1
1 - sum(diag(tab1))/sum(tab1)

# Misclassification error - test data
p2 <- predict(mymodel, test, type = 'response')
pred2 <- ifelse(p2>0.5, 1, 0)
tab2 <- table(Predicted = pred2, Actual = test$admit)
tab2
1 - sum(diag(tab2))/sum(tab2)

# ROC curve  receiver operating characteristic

library(ROCR)
pred <- predict(mymodel , train , type ='prob')
#ROC package command prediction 
pred <- prediction( pred , train$admit)
roc <- performance ( pred , 'tpr' , 'fpr' )
plot(roc)
abline(a=0, b=1)




AUC 

auc <- performance(pred , 'auc')
auc <-unlist(slot(auc ,"y.values" ))

Accuracy vs cutoff

pred <- predict(mymodel , binary , type ='prob')
hist(pred)
pred <- prediction( pred , train$admit)
eval <- performance( pred, 'acc')
plot( eval)
abline(h=.7 , v=.5)


acc_tab <- cbind(  slot(eval ,"y.values" )[[1]], slot(eval ,"y.values" )[[1]])
or 
cbind(unlist(slot(eval ,"y.values" )), unlist(slot(eval ,"x.values")))

max<- which.max(slot(eval ,"y.values" )[[1]])
acc<- slot(eval ,"y.values" )[[1]][max]
cut <- slot(eval ,"x.values" )[[1]][max]
cbind (acc, cut)

## precision/recall curve (x-axis: recall, y-axis: precision)
perf1 <- performance(pred, "prec", "rec")
plot(perf1)

## sensitivity/specificity curve (x-axis: specificity,
## y-axis: sensitivity)  ----same as above
perf1 <- performance(pred, "sens", "spec")
plot(perf1)

Stratified split

stratified(mydata, rank, .3, seed = 1000)






